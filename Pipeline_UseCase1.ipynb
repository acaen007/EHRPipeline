{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, rdflib, pickle\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# Custom EHR Tools \n",
    "from EHRPipeline.entity_alignment.invokers import Invoker\n",
    "from EHRPipeline.entity_alignment.entity_alignement import CrossOntologyAligner\n",
    "from EHRPipeline.entity_alignment.embedder import SimpleDataEmbedder, ClusterGenerator\n",
    "from EHRPipeline.entity_linking.linking_validation import LinkingValidator\n",
    "from EHRPipeline.fact_validation.factValidation import Validator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General setup of environment and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = \"merged_ontology.ttl\"\n",
    "tokenizer = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "baseKG = rdflib.Graph()\n",
    "baseKG.parse(basePath, format=\"ttl\") \n",
    "\n",
    "snomed_embeddings = Path(\"../data/snomed_embedded.pkl\")\n",
    "clusters = Path(\"../sven/data/cluster.pkl\")\n",
    "\n",
    "if snomed_embeddings.exists():\n",
    "    with open(\"../data/snomed_embedded.pkl\", \"rb\") as file:\n",
    "        data_embedding = pickle.load(file)\n",
    "else:\n",
    "    snomed = rdflib.Graph()\n",
    "    snomed.parse(\"../data/snomed-ct-20221231-mini.ttl\", format=\"ttl\")\n",
    "    embedder = SimpleDataEmbedder(embeddingModel=tokenizer)\n",
    "    data_embedding = embedder.encode(data=snomed)\n",
    "\n",
    "if clusters.exists():\n",
    "    with open(\"../sven/data/cluster.pkl\", \"rb\") as file1:\n",
    "        segmentation = pickle.load(file1)\n",
    "else:\n",
    "    cluster = ClusterGenerator(data_embedding, n_clusters=50)\n",
    "    segmentation = cluster.generate_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Fluvio's part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Ontology Entity Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologyaligner = CrossOntologyAligner(dataGraph=data_embedding, clusters=segmentation, embeddingModel=tokenizer)\n",
    "CrossOntologyAlignedKG = ontologyaligner.merge(query=baseKG, Invoker=\"icd9tosnomed\", Namespace=rdflib.URIRef(\"https://biomedit.ch/rdf/sphn-schema/sphn#hasCode\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Linking Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinkingValidator(CrossOntologyAlignedKG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rdf graph to triples:\n",
    "triples = []\n",
    "for vertex, edge, label in alignedGraph:\n",
    "    triples.append((str(vertex), str(edge), str(label)))\n",
    "\n",
    "# Andy's code\n",
    "training, validation, testing = triples.split([0.8, 0.1, 0.1])\n",
    "\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    validation=validation,\n",
    "    testing=testing,\n",
    "    model='TransE',\n",
    "    model_kwargs={\n",
    "        'embedding_dim': 20,\n",
    "    },\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs={\n",
    "        'lr': 1e-3,\n",
    "        'weight_decay': 1e-5\n",
    "    },\n",
    "    negative_sampler='basic',\n",
    "    loss='SoftplusLoss',\n",
    "    training_loop='sLCWA',\n",
    "    training_kwargs={\n",
    "        'num_epochs': 100,\n",
    "        'batch_size': 32,\n",
    "        'label_smoothing': 0.0\n",
    "    },\n",
    "    evaluator_kwargs=  {\n",
    "        \"filtered\": True\n",
    "    },\n",
    "    filter_validation_when_testing = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    sparql_endpoint = \"http://localhost:7200/repositories/finalrepohealthcare\" # This is a localhost so has to be configured per machine\n",
    "    validator = Validator(sparql_endpoint)\n",
    "\n",
    "    predictions_file = \"predictions.txt\"\n",
    "    output_file = \"validated_facts.txt\"\n",
    "    \n",
    "    with open(predictions_file, \"r\", encoding=\"utf-8\") as f_in, open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Expect exactly 3 parts: subject, predicate, object\n",
    "            parts = line.split()\n",
    "            if len(parts) != 3:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "            \n",
    "            subj = parts[0].strip()\n",
    "            pred = parts[1].strip()\n",
    "            obj  = parts[2].strip()\n",
    "\n",
    "            subj_uri = subj.strip(\"<>\")\n",
    "            pred_uri = pred.strip(\"<>\")\n",
    "            obj_uri  = obj.strip(\"<>\")\n",
    "\n",
    "            # Validate\n",
    "            score = validator.validate_fact(subj_uri, pred_uri, obj_uri, max_length=3)\n",
    "\n",
    "            print(f\"Fact: {subj} {pred} {obj} => Score: {score}\")\n",
    "\n",
    "            # threshold for writing the facts validated\n",
    "            if score >= 0.5:\n",
    "                f_out.write(f\"{subj} {pred} {obj}\\n\")\n",
    "\n",
    "    print(f\"Validation complete. Facts with score >= 0.5 are in '{output_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
