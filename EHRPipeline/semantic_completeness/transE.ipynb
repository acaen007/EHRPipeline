{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pykeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bernardocosta/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "using automatically assigned random_state=183999714\n",
      "No random seed is specified. Setting to 1461782988.\n",
      "No cuda devices were available. The model runs on CPU\n",
      "Training epochs on cpu: 100%|██████████| 150/150 [01:23<00:00,  1.80epoch/s, loss=0.492, prev_loss=0.493]\n",
      "WARNING:pykeen.utils:Using automatic batch size on device.type='cpu' can cause unexplained out-of-memory crashes. Therefore, we use a conservative small batch_size=32. Performance may be improved by explicitly specifying a larger batch size.\n",
      "Evaluating on cpu:   0%|          | 0.00/2.21k [00:00<?, ?triple/s]WARNING:torch_max_mem.api:Encountered tensors on device_types={'cpu'} while only ['cuda'] are considered safe for automatic memory utilization maximization. This may lead to undocumented crashes (but can be safe, too).\n",
      "Evaluating on cpu: 100%|██████████| 2.21k/2.21k [00:02<00:00, 785triple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 2.86s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineResult(random_seed=1461782988, model=TransE(\n",
      "  (loss): SoftplusLoss(\n",
      "    (margin_activation): Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      "  (interaction): TransEInteraction()\n",
      "  (entity_representations): ModuleList(\n",
      "    (0): Embedding(\n",
      "      (_embeddings): Embedding(7714, 20)\n",
      "    )\n",
      "  )\n",
      "  (relation_representations): ModuleList(\n",
      "    (0): Embedding(\n",
      "      (_embeddings): Embedding(5, 20)\n",
      "    )\n",
      "  )\n",
      "  (weight_regularizers): ModuleList()\n",
      "), training=TriplesFactory(num_entities=7714, num_relations=5, create_inverse_triples=False, num_triples=17674, path=\"/Users/bernardocosta/Desktop/EHRPipeline/EHRPipeline/semantic_completeness/formatted_triples_FINAL.txt\"), training_loop=<pykeen.training.slcwa.SLCWATrainingLoop object at 0x30434ad70>, losses=[2.0380067797293497, 1.763980762867988, 1.6679241961208433, 1.6002589554726323, 1.537342095892425, 1.477626315292786, 1.4215251959685176, 1.3699311822060003, 1.3225472941321017, 1.2791590324146622, 1.239633094984196, 1.2037612033795706, 1.1708169017950407, 1.1400310510321507, 1.1116081652977583, 1.08486743495003, 1.0598233759295446, 1.0363197263067496, 1.0140555466493257, 0.9928663909758625, 0.9730394054709464, 0.9540003178132593, 0.9355589652578826, 0.9180076393900038, 0.9014039036378292, 0.885803787337505, 0.8703077130464274, 0.8552227244454741, 0.8414374575908102, 0.8279574330202278, 0.8147700090520421, 0.802486204217183, 0.7903945807091366, 0.7788787886203952, 0.7680282470977328, 0.7579299929344633, 0.7476954598107778, 0.7374797672518338, 0.7274100558451675, 0.718838733639467, 0.7092733388567919, 0.7010635501868471, 0.6925682911605558, 0.6845259793628189, 0.6763450072212633, 0.6689480982896001, 0.6611372335909935, 0.6543913118231361, 0.6464031751505074, 0.6393589998240066, 0.632485595577233, 0.6260510281024747, 0.6209816533876802, 0.6137525194592329, 0.60805523438652, 0.6017391468258491, 0.5954506152577254, 0.5895432367462793, 0.5844644438509053, 0.5794072997289799, 0.5755886490478653, 0.5691350406375975, 0.5651509507439667, 0.5612139462023489, 0.5575949473148228, 0.5534580925489636, 0.5511546408720517, 0.5452771429342991, 0.5408876394384808, 0.5394813774615042, 0.5359619561091038, 0.5330900804798168, 0.5303240072446964, 0.5266211422507198, 0.5245494370973562, 0.520643636018415, 0.5166773185484232, 0.5158739749604927, 0.5133519095602777, 0.511513417280173, 0.5089852552840766, 0.5088617053644136, 0.506609493472477, 0.5071160144443754, 0.5051100641004, 0.5050581008680906, 0.5017717694611058, 0.5021340176597857, 0.501543466264473, 0.5004063579531733, 0.49876630230794977, 0.49968841009071036, 0.498876933756185, 0.49864463866511477, 0.49869117620409503, 0.49756676378991677, 0.4957119910346233, 0.4940436836500495, 0.49520866122858004, 0.4962121366807824, 0.49810578023331076, 0.49440716231278875, 0.4968915133859969, 0.4948540939991556, 0.49436594225183317, 0.49536234576922, 0.4946906636679582, 0.494969405867092, 0.4946261394843055, 0.49421876765935807, 0.49414541767691184, 0.4918161407517266, 0.49336503454185954, 0.49283224096349953, 0.4918173896468785, 0.4943306634158812, 0.49376057290470404, 0.49312561718076736, 0.4929443006058498, 0.49321269266859746, 0.49339384438763045, 0.4924423719939875, 0.49404204074987235, 0.4922937108422705, 0.4934634578702247, 0.4918914748790251, 0.49350504913985405, 0.4938598892248992, 0.4939082627593932, 0.49441973549763507, 0.49329037940092585, 0.49312493399081997, 0.4931539146206047, 0.49251848917326485, 0.49200356701830195, 0.4912937247947155, 0.4951563607935017, 0.4913873622904634, 0.49160166356921414, 0.4913926849960203, 0.4947474304094884, 0.49129021447993965, 0.4938955774790124, 0.49262601670692885, 0.4931682772382043, 0.49453091519003967, 0.49318776655585167, 0.4929803858290529, 0.49283843488848444, 0.4924898529138962], metric_results=<pykeen.evaluation.rank_based_evaluator.RankBasedMetricResults object at 0x305e516c0>, train_seconds=83.57290577888489, evaluate_seconds=2.8577957153320312, stopper=<pykeen.stoppers.stopper.NopStopper object at 0x30434af50>, configuration={'dataset': '<user defined>', 'training': '<user defined>', 'testing': '<user defined>', 'validation': '<user defined>', 'model': 'TransE', 'model_kwargs': {'embedding_dim': 20, 'random_seed': 1461782988, 'loss': SoftplusLoss(\n",
      "  (margin_activation): Softplus(beta=1.0, threshold=20.0)\n",
      "), 'scoring_fct_norm': 1, 'power_norm': False, 'entity_initializer': <function xavier_uniform_ at 0x17f757f40>, 'entity_constrainer': <function normalize at 0x17b350dc0>, 'relation_initializer': <pykeen.utils.compose object at 0x17f7746a0>, 'relation_constrainer': None, 'regularizer': None, 'regularizer_kwargs': None}, 'loss_kwargs': None, 'regularizer_kwargs': None, 'optimizer': 'Adam', 'optimizer_kwargs': {'lr': 0.001, 'weight_decay': 1e-05, 'betas': (0.9, 0.999), 'eps': 1e-08, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None}, 'negative_sampler': 'BasicNegativeSampler', 'negative_sampler_kwargs': None, 'training_loop': 'SLCWATrainingLoop', 'training_loop_kwargs': {'negative_sampler': <class 'pykeen.sampling.basic_negative_sampler.BasicNegativeSampler'>, 'negative_sampler_kwargs': None}, 'evaluator': 'RankBasedEvaluator', 'evaluator_kwargs': {'filtered': True}, 'num_epochs': 150, 'batch_size': 32, 'label_smoothing': 0.1, 'evaluation_kwargs': {'additional_filter_triples': {'training': {'sha512': 'fcc30af639c72cf73de6f8af4699127b8efbfc8a9ea7b4634bc9cff22a6a39364b95a68d76d3d3935dd6484594796a6333b7d5303031f32f238b87e9e73e72a9'}, 'validation': {'sha512': 'd37e89ba4e14e19e37721114a25037f43a2212492efd0fa2dd5e96dd5964252935b50423a1cc7d64f4b6b82b4dafaf950777438fccf9e464e74d81a9c8c663ef'}}}}, metadata={}, version='1.11.0', git_hash='UNHASHED')\n"
     ]
    }
   ],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "triples_factory = TriplesFactory.from_path('formatted_triples_FINAL.txt')\n",
    "training, validation, testing = triples_factory.split([0.8, 0.1, 0.1])\n",
    "\n",
    "\n",
    "\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    validation=validation,\n",
    "    testing=testing,\n",
    "\n",
    "    model='transE',\n",
    "    model_kwargs={\n",
    "        'embedding_dim': 20,\n",
    "    },\n",
    "\n",
    "    optimizer='Adam',\n",
    "    optimizer_kwargs={\n",
    "        'lr': 1e-3,\n",
    "        'weight_decay': 1e-5\n",
    "    },\n",
    "\n",
    "    negative_sampler='basic',\n",
    "    # negative_sampler_kwargs={\n",
    "    #     'num_negs_per_pos': 1\n",
    "    # },\n",
    "\n",
    "    loss='SoftplusLoss',\n",
    "\n",
    "    training_loop='sLCWA',\n",
    "\n",
    "    training_kwargs={\n",
    "        'num_epochs': 150,\n",
    "        'batch_size': 32,\n",
    "        'label_smoothing': 0.1\n",
    "    },\n",
    "\n",
    "    evaluator_kwargs=  {\n",
    "        # 'batch_size': 64,\n",
    "        \"filtered\": True\n",
    "    },\n",
    "    filter_validation_when_testing = True,\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/bernardocosta/Desktop/EHRPipeline/EHRPipeline/semantic_completeness/transE.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bernardocosta/Desktop/EHRPipeline/EHRPipeline/semantic_completeness/transE.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Plot the training loss by epoch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bernardocosta/Desktop/EHRPipeline/EHRPipeline/semantic_completeness/transE.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result\u001b[39m.\u001b[39;49mplot_losses()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pykeen/pipeline/api.py:322\u001b[0m, in \u001b[0;36mPipelineResult.plot_losses\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Plot the losses per epoch.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[39m:param kwargs: The keyword arguments passed to :func:`pykeen.pipeline.plot_utils.plot_losses`.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m:returns: The axis\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mplot_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_losses\n\u001b[0;32m--> 322\u001b[0m \u001b[39mreturn\u001b[39;00m plot_losses(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/pykeen/pipeline/plot_utils.py:26\u001b[0m, in \u001b[0;36mplot_losses\u001b[0;34m(pipeline_result, ax)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_losses\u001b[39m(pipeline_result, \u001b[39m*\u001b[39m, ax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     25\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Plot the losses per epoch.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     sns\u001b[39m.\u001b[39mset_style(\u001b[39m\"\u001b[39m\u001b[39mdarkgrid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m     ax \u001b[39m=\u001b[39m _ensure_ax(ax)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Plot the training loss by epoch\n",
    "result.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tail_id</th>\n",
       "      <th>score</th>\n",
       "      <th>tail_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>7482</td>\n",
       "      <td>-0.490115</td>\n",
       "      <td>icd9#25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>7494</td>\n",
       "      <td>-0.530894</td>\n",
       "      <td>icd9#4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>7492</td>\n",
       "      <td>-0.551320</td>\n",
       "      <td>icd9#311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>7505</td>\n",
       "      <td>-0.672903</td>\n",
       "      <td>icd9#5119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>7488</td>\n",
       "      <td>-0.674284</td>\n",
       "      <td>icd9#2859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>7514</td>\n",
       "      <td>-0.680279</td>\n",
       "      <td>icd9#5849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>7507</td>\n",
       "      <td>-0.690865</td>\n",
       "      <td>icd9#51881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>7522</td>\n",
       "      <td>-0.736446</td>\n",
       "      <td>icd9#7907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>7480</td>\n",
       "      <td>-0.752592</td>\n",
       "      <td>icd9#20300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>7485</td>\n",
       "      <td>-0.921460</td>\n",
       "      <td>icd9#2762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tail_id     score  tail_label\n",
       "7482     7482 -0.490115  icd9#25000\n",
       "7494     7494 -0.530894   icd9#4019\n",
       "7492     7492 -0.551320    icd9#311\n",
       "7505     7505 -0.672903   icd9#5119\n",
       "7488     7488 -0.674284   icd9#2859\n",
       "7514     7514 -0.680279   icd9#5849\n",
       "7507     7507 -0.690865  icd9#51881\n",
       "7522     7522 -0.736446   icd9#7907\n",
       "7480     7480 -0.752592  icd9#20300\n",
       "7485     7485 -0.921460   icd9#2762"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pykeen import predict  # or pykeen.models.predict, depending on version\n",
    "\n",
    "df_predictions = predict.predict_target(\n",
    "    model=result.model,\n",
    "    head=\"Diagnosis/10033/PATIENTS/112578\",\n",
    "    relation=\"hasCode\",\n",
    "    triples_factory=result.training\n",
    ").df\n",
    "\n",
    "# Inspect the top 10\n",
    "df_predictions.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Fact Validation - Generate a csv with the previsions from the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote top-10 predictions to ../fact_validation/predictions.txt\n"
     ]
    }
   ],
   "source": [
    "output_file = \"../fact_validation/predictions.txt\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, row in df_predictions.head(10).iterrows():\n",
    "        predicted_code = row[\"tail_label\"] \n",
    "        subject_uri = \"<http://example.org/Diagnosis/10033/PATIENTS/112578>\"\n",
    "        predicate_uri = \"<https://biomedit.ch/rdf/sphn-schema/sphn#hasCode>\"\n",
    "        object_uri = f\"<http://example.org/Code/{predicted_code}>\"\n",
    "\n",
    "        triple_line = f\"{subject_uri}  {predicate_uri}  {object_uri}\"\n",
    "        f.write(triple_line + \"\\n\")\n",
    "\n",
    "print(f\"Wrote top-10 predictions to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
